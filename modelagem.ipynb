{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## Configuração Inicial"
   ],
   "metadata": {
    "collapsed": false,
    "id": "gTwmW32LdbDo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configuração e import de bibliotecas."
   ],
   "metadata": {
    "collapsed": false,
    "id": "5tpyf1WZdbDp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from os import getcwd\n",
    "from tensorflow import keras\n",
    "from funcoes_locais import redimensionar_dataset, processar_imagem\n",
    "\n",
    "diretorio_treino = 'asl-alphabet/asl_alphabet_train/asl_alphabet_train/'\n",
    "diretorio_teste = 'asl-alphabet/asl_alphabet_test/'\n",
    "diretorio_atual = getcwd()"
   ],
   "metadata": {
    "id": "Ct74BCICdbDp",
    "ExecuteTime": {
     "end_time": "2023-09-22T23:21:18.600906900Z",
     "start_time": "2023-09-22T23:21:18.501189500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Importação dos dados - via diretório\n",
    "\n",
    "Essa é a forma ideal de importar os dados, já que ela permite a separação das bases de treino e validação no momento da importação.\n",
    "Porém, precisamos pegar apenas uma parte das bases de treino e validação para fins de velocidade do treino.\n",
    "Para isso, será usado o módulo preprocessar_local, irá manter apenas N amostras por classe."
   ],
   "metadata": {
    "id": "CeWSVpgaKqj4"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset redimensionado para 75 amostras por classe.\n"
     ]
    }
   ],
   "source": [
    "redimensionar_dataset(75)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-22T23:21:18.617965900Z",
     "start_time": "2023-09-22T23:21:18.525225200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Agora, será montado o dataset de treino, validação e teste, usando keras."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_dataset = keras.utils.image_dataset_from_directory(\n",
    "    diretorio_treino,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(200, 200),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.25,\n",
    "    subset='training',\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset = keras.utils.image_dataset_from_directory(\n",
    "    diretorio_treino,\n",
    "    labels='inferred',\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(200, 200),\n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    validation_split=0.25,\n",
    "    subset='validation',\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")\n",
    "\n",
    "\n",
    "test_dataset = keras.utils.image_dataset_from_directory(\n",
    "    diretorio_teste,\n",
    "    labels=list(range(0,28)),\n",
    "    label_mode='int',\n",
    "    class_names=None,\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    image_size=(200, 200),\n",
    "    shuffle=False,\n",
    "    seed=None,\n",
    "    validation_split=None,\n",
    "    subset=None,\n",
    "    interpolation='bilinear',\n",
    "    follow_links=False,\n",
    "    crop_to_aspect_ratio=False\n",
    ")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ArWkm5P29Mm3",
    "outputId": "d7316100-07dc-4674-e0f3-202ddea23278",
    "ExecuteTime": {
     "end_time": "2023-09-23T00:10:42.512899Z",
     "start_time": "2023-09-23T00:10:42.402899800Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'keras' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_864\\2966408458.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m train_dataset = keras.utils.image_dataset_from_directory(\n\u001B[0m\u001B[0;32m      2\u001B[0m     \u001B[0mdiretorio_treino\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m     \u001B[0mlabels\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'inferred'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m     \u001B[0mlabel_mode\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'int'\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m     \u001B[0mclass_names\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'keras' is not defined"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tendo as imagens carregadas, vamos aplicar a função de pré-processamento, para assim podermos alimentar o modelo:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_ds = train_dataset.map(lambda x, y: tf.py_function(processar_imagem, [x, y], [tf.float32, tf.int32]))\n",
    "val_ds = val_dataset.map(lambda x, y: (tf.py_function(processar_imagem, [x, y], [tf.float32, tf.uint32])))\n",
    "test_ds = test_dataset.map(lambda x, y: (tf.py_function(processar_imagem, [x, y], [tf.float32, tf.int32])))"
   ],
   "metadata": {
    "id": "aci-85NOHutT",
    "ExecuteTime": {
     "end_time": "2023-09-22T23:21:20.101577400Z",
     "start_time": "2023-09-22T23:21:19.974623100Z"
    }
   },
   "execution_count": 7,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "#  Configuração de Pipeline\n",
    "\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset = train_dataset.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\n",
    "val_dataset = val_dataset.cache().prefetch(buffer_size=AUTOTUNE)"
   ],
   "metadata": {
    "id": "8z6uS0mHT_Mn",
    "ExecuteTime": {
     "end_time": "2023-09-22T23:21:20.139676100Z",
     "start_time": "2023-09-22T23:21:20.099576600Z"
    }
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "51/51 [==============================] - ETA: 0s - loss: 3.8881 - accuracy: 0.0551\n",
      "Epoch 1: val_loss improved from inf to 3.52902, saving model to C:\\Users\\Kafat\\PycharmProjects\\ProjetoAvanti\\Checkpoint_model.hdf5\n",
      "51/51 [==============================] - 46s 671ms/step - loss: 3.8881 - accuracy: 0.0551 - val_loss: 3.5290 - val_accuracy: 0.0203 - lr: 0.0070\n",
      "Epoch 2/6\n",
      "51/51 [==============================] - ETA: 0s - loss: 4.0100 - accuracy: 0.0447\n",
      "Epoch 2: val_loss improved from 3.52902 to 3.43768, saving model to C:\\Users\\Kafat\\PycharmProjects\\ProjetoAvanti\\Checkpoint_model.hdf5\n",
      "51/51 [==============================] - 30s 599ms/step - loss: 4.0100 - accuracy: 0.0447 - val_loss: 3.4377 - val_accuracy: 0.0460 - lr: 0.0070\n",
      "Epoch 3/6\n",
      "51/51 [==============================] - ETA: 0s - loss: 4.1084 - accuracy: 0.0343\n",
      "Epoch 3: val_loss did not improve from 3.43768\n",
      "51/51 [==============================] - 29s 571ms/step - loss: 4.1084 - accuracy: 0.0343 - val_loss: 3.4663 - val_accuracy: 0.0460 - lr: 0.0070\n",
      "Epoch 4/6\n",
      "51/51 [==============================] - ETA: 0s - loss: 4.0158 - accuracy: 0.0362\n",
      "Epoch 4: val_loss did not improve from 3.43768\n",
      "51/51 [==============================] - 29s 575ms/step - loss: 4.0158 - accuracy: 0.0362 - val_loss: 3.4822 - val_accuracy: 0.0460 - lr: 0.0070\n",
      "Epoch 5/6\n",
      "51/51 [==============================] - ETA: 0s - loss: 4.0279 - accuracy: 0.0306\n",
      "Epoch 5: val_loss did not improve from 3.43768\n",
      "51/51 [==============================] - 29s 576ms/step - loss: 4.0279 - accuracy: 0.0306 - val_loss: 3.4923 - val_accuracy: 0.0405 - lr: 0.0070\n",
      "Epoch 6/6\n",
      " 6/51 [==>...........................] - ETA: 24s - loss: 4.0532 - accuracy: 0.0312"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "num_classes = 29\n",
    "\n",
    "pretrained_base = tf.keras.applications.inception_v3.InceptionV3(\n",
    "    include_top=False,\n",
    "    weights='imagenet',\n",
    "    input_tensor=None,\n",
    "    input_shape=(200, 200, 3),\n",
    "    pooling='max',\n",
    "    classes=num_classes,\n",
    "    classifier_activation='softmax'\n",
    ")\n",
    "\n",
    "pretrained_base.Trainable = False\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    pretrained_base,\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.3),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(rate=0.2),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    min_delta=0.00001,\n",
    "    monitor='val_loss',\n",
    "    patience=16,\n",
    "    restore_best_weights=True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "check_point = ModelCheckpoint(\n",
    "    diretorio_atual,\n",
    "    monitor='val_loss',\n",
    "    verbose=1,\n",
    "    save_best_only=True,\n",
    "    save_weights_only=False,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',\n",
    "                              factor=0.7,\n",
    "                              patience=5,\n",
    "                              min_lr=0.0001)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.SGD(learning_rate=0.007),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "epochs = 6\n",
    "\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=val_dataset,\n",
    "    epochs=epochs,\n",
    "    callbacks=[early_stopping, check_point, reduce_lr],\n",
    "    workers=3\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2023-09-22T23:21:20.129623900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ]
}
