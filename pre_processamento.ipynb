{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "**Pré-processamentos**:\n",
    "\n",
    "- **Remoção de fundo**: Remover o fundo da imagem para reduzir a complexidade do aprendizado pelo modelo, dada a variabilidade de cores, contraste e iluminação entre as imagens;\n",
    "\n",
    "- **Conversão para escala de cinza**: Como a cor não é uma informação relevante para detecção do gesto, as imagens serão convertidas para escala de cinza;\n",
    "\n",
    "- **Realce e ajuste de iluminaçao**: aplicação de maior contraste nas cores da imagem para aprimorar o facilitar a detecção da posição dedos na frente da palma da mão. Além disso, diferentes imagens estao com diferentes níveis de iluminação. Dessa forma, corrigir as variaçoes de iluminação para dar destaque às mãos;\n",
    "\n",
    "- **Suavização para redução de ruídos**: Aplicar filtros de suavizaçao para reduçao de ruídos afim de facilitar a detecçao das bordas;\n",
    "\n",
    "- **Detecção de borda**: Detecção das bordas para mapear o formato exato da mão;\n",
    "\n",
    "- **Normalização**: Normalizar os pixels da imagem;\n",
    "\n",
    "- **Segmentação**: Há imagens em que o antebraço está completamente exposto, enquanto que há imagens em que o antebraço praticamente não aparece. Nesse caso, segmentar apenas a mão é importante;"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Configuração Inicial"
   ],
   "metadata": {
    "collapsed": false,
    "id": "gTwmW32LdbDo"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Configuração e import de bibliotecas, além da definição da imagem de referência."
   ],
   "metadata": {
    "collapsed": false,
    "id": "5tpyf1WZdbDp"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from rembg import remove\n",
    "from tensorflow import keras, data\n",
    "from funcoes_locais import redimensionar_dataset\n",
    "from opendatasets import download\n",
    "from statistics import geometric_mean\n",
    "from math import log10\n",
    "\n",
    "plt.rcParams['axes.grid'] = False  # Desativa as grades nos plots.\n",
    "\n",
    "imagem = cv2.imread('asl-alphabet/asl_alphabet_train/asl_alphabet_train/S/S55.jpg')\n",
    "image_rgb = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)"
   ],
   "metadata": {
    "id": "Ct74BCICdbDp"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Download de Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "A célula abaixo realiza o download do dataset diretamente usando a API do Kaggle em seu repositório local e o redimensiona, eliminando o excesso de amostras.  "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "download(\"https://www.kaggle.com/datasets/grassknoted/asl-alphabet\")\n",
    "redimensionar_dataset(75)  # Vamos usar apenas 75 amostras por classe."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Primeiras Impressões das Imagens"
   ],
   "metadata": {
    "collapsed": false,
    "id": "jkd4OnlTdbDr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos plotar a imagem de referência para termos a primeira impressão, e a partir disso, realizar o pré-processamento."
   ],
   "metadata": {
    "collapsed": false,
    "id": "MCpO1FC1dbDr"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SUofddaOdbDr",
    "outputId": "b0b87c9d-6814-4cb0-d754-04e8140e25be",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    }
   },
   "outputs": [],
   "source": [
    "plt.imshow(image_rgb)\n",
    "plt.title(\"Imagem de Referência , S87.\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Vamos agora, explorar as propriedades da imagem, como suas dimensões e tipo de encoding."
   ],
   "metadata": {
    "collapsed": false,
    "id": "oDiVTc1HdbDs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnh2rrB3dbDt",
    "outputId": "29bbd77f-c8dd-41ca-c3fb-097e5673c31b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    }
   },
   "outputs": [],
   "source": [
    "altura, largura, canais = imagem.shape\n",
    "\n",
    "propriedades = [\n",
    "    ('Altura:', altura),\n",
    "    ('Largura:', largura),\n",
    "    ('Canais de cor:', canais),\n",
    "    ('Tipo de dado:', imagem.dtype),\n",
    "    ('Desvio Padrão', imagem.std())\n",
    "]\n",
    "\n",
    "for propriedade, valor_propriedade in propriedades:\n",
    "    print(f'{propriedade} {valor_propriedade}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UDgP6OAfdbDu"
   },
   "source": [
    "Passando para os canais da imagem, vamos usar a função np.asarray(), que irá tabular a imagem em forma numérica, possibilitando a separação de canais.  \n",
    "Tendo em vista cada canal separado, é possível analisar qual cor possui o maior impacto no elemento desejado da imagem, possibilitando aplicar outras operações.\n",
    "Abaixo, o código para separação e representação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "matriz_imagem = np.asarray(imagem)\n",
    "\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.subplot(141)\n",
    "\n",
    "plt.imshow(imagem)\n",
    "plt.title(\"Imagem Original\")\n",
    "plt.subplot(142)\n",
    "\n",
    "plt.imshow(matriz_imagem[:, :, 1], cmap=\"Reds\")\n",
    "plt.title(\"Canal R\")\n",
    "plt.subplot(143)\n",
    "\n",
    "plt.imshow(matriz_imagem[:, :, 1], cmap=\"Greens\")\n",
    "plt.title(\"Canal G\")\n",
    "plt.subplot(144)\n",
    "\n",
    "plt.imshow(matriz_imagem[:, :, 2], cmap=\"Blues\")\n",
    "plt.title(\"Canal B\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "fusccPISdbDu",
    "outputId": "2a1c8190-1dcd-4c83-f089-8f962efcc8a5",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Pré-processamento de Imagens"
   ],
   "metadata": {
    "collapsed": false,
    "id": "5yT2RdGRdbDu"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Começaremos por remover o fundo da imagem, para facilitar o processamento."
   ],
   "metadata": {
    "id": "9dh7dq5KMY9C"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "img_sem_fundo = remove(image_rgb)\n",
    "\n",
    "plt.imshow(img_sem_fundo)\n",
    "plt.title('Imagem sem fundo')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "vWP5MMDnMfDE",
    "outputId": "00d9108f-3454-4f8b-d4b2-05f5237732ae"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Como os gestos não são dependentes de cores para serem reconhecidos, mas sim dos formatos, vamos converter a imagem para preto e branco.  \n",
    "Trabalhar com imagens na escala cinza também reduz o custo computacional para realizar processos nas imagems."
   ],
   "metadata": {
    "collapsed": false,
    "id": "jKQwoXzodbDv"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "imagem_cinza = cv2.cvtColor(img_sem_fundo, cv2.COLOR_RGB2GRAY)  # Conversão para escala cinza.\n",
    "plt.imshow(imagem_cinza, cmap=\"gray\")\n",
    "plt.title(\"Imagem em Escala Cinza\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "KCas613ddbDv",
    "outputId": "606f2c4c-6a32-439c-9bbc-bae20354b4f1",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Uma vez na escala de cinza, a fim de ajustar o contraste e facilitar a identificaçao das principais características da imagem, aplica-se técnicas de realce."
   ],
   "metadata": {
    "id": "hfHZZs4tz_Mq"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Realce por filtro linear\n",
    "alpha = 40/(1.7*imagem_cinza.mean())\n",
    "img_equal = cv2.convertScaleAbs(imagem_cinza, alpha = alpha, beta = 8)\n",
    "img_equal = cv2.GaussianBlur(img_equal, (5,5), 0.9, 0.9)\n",
    "\n",
    "# Realce por correção gama:\n",
    "vetor = [i+1 for i in np.reshape(imagem_cinza, -1)] #conversao de imagem cinza para uma dimensao\n",
    "gamma = log10(200/255)/log10(geometric_mean(vetor)) #calculo do melhor gama\n",
    "img_gamma = (np.power(imagem_cinza/255, gamma)*255).astype(np.uint8)\n",
    "img_gamma = cv2.GaussianBlur(img_gamma, (5,5), 0.7, 0.7)\n",
    "\n",
    "# Obtenção dos histogramas:\n",
    "hist_cinza = cv2.calcHist([imagem_cinza],[0],None,[255],[1,256])\n",
    "hist_equal = cv2.calcHist([img_equal],[0],None,[255],[1,256])\n",
    "hist_gamma = cv2.calcHist([img_gamma],[0], None, [255], [1, 256])\n",
    "\n",
    "# Impressão das imagens\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(imagem_cinza, cmap='gray')\n",
    "plt.title(\"Imagem original\")\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "plt.plot(hist_cinza, color='black')\n",
    "plt.title('Histograma da imagem em tons de cinza')\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(img_equal, cmap='gray')\n",
    "plt.title(\"Imagem realçada linearmente\")\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "plt.plot(hist_equal, color='black')\n",
    "plt.title('Histograma da imagem realçada linearmente')\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(img_gamma, cmap='gray')\n",
    "plt.title('Imagem realçada por gama')\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "plt.plot(hist_gamma, color='black')\n",
    "plt.title('Histograma da imagem realçada por gama')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 862
    },
    "id": "BiNzeBdC0xzO",
    "outputId": "d94c9fe8-d10f-48f3-86b8-4e7e978f0cde"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "img_canny1 = cv2.Canny(imagem_cinza, threshold1=90,threshold2=200)\n",
    "img_canny2 = cv2.Canny(img_equal, threshold1=90,threshold2=200)\n",
    "img_canny3 = cv2.Canny(img_gamma, threshold1=90, threshold2=200)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.imshow(imagem_cinza, cmap='gray')\n",
    "plt.title('Imagem cinza')\n",
    "plt.subplot(3,2,2)\n",
    "plt.imshow(img_canny1, cmap='gray')\n",
    "plt.title('Canny imagem cinza')\n",
    "plt.subplot(3,2,3)\n",
    "plt.imshow(img_equal, cmap='gray')\n",
    "plt.title('Imagem realçada linearmente')\n",
    "plt.subplot(3,2,4)\n",
    "plt.imshow(img_canny2, cmap='gray')\n",
    "plt.title('Canny imagem realçada')\n",
    "plt.subplot(3,2,5)\n",
    "plt.imshow(img_gamma, cmap='gray')\n",
    "plt.title('Imagem realçada por gamma')\n",
    "plt.subplot(3,2,6)\n",
    "plt.imshow(img_canny3, cmap='gray')\n",
    "plt.title('Canny gama')\n",
    "\n",
    "plt.tight_layout()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 977
    },
    "id": "7nefS2SC4Fd1",
    "outputId": "e2a38d71-1b85-4365-f1e1-421ebaf89c14"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Percebe-se que Canny apresentou um desempenho melhor que Sobel.\n",
    "\n",
    "Além disso, para aplicação de Canny, não precisa realizar o realce da imagem. O próprio algoritmo de Canny\n",
    "realiza o cálculo dos gradientes aplicando sobel para encontrar as bordas e também aplica um um filtro gaussiano\n",
    "para redução de ruído."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Para processamento da imagem pela rede neural, é importante a normalizaçao de seus pixels."
   ],
   "metadata": {
    "id": "tAh-5lU8rkjJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "img_norm = img_canny3/255\n",
    "\n",
    "plt.imshow(img_norm, cmap='gray')\n",
    "plt.title(\"Imagem gama normalizada.\")\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "uN_f5SUprrKK",
    "outputId": "d395f389-9f43-40da-c156-f485f95a00d5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "O pré-processamento final ficou conforme função abaixo.\n",
    "Neste caso, está descrito também no módulo funcoes_locais, para ser usado em outros notebooks.   \n",
    "Com isso, foi encerrado a análise exploratória, e vamos ao notebook de modelagem para realizar o treinamento."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "\"\"\"\n",
    "def preprocessar_imagem(imagem_cv2):\n",
    "        img = cv2.imread(imagem_cv2)\n",
    "        img_no_back = remove(img)\n",
    "        img_gray = cv2.cvtColor(img_no_back, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "        alpha = 40 / (1.7 * img_gray.mean())\n",
    "        img_equal = cv2.convertScaleAbs(img_gray, alpha=alpha, beta=8)\n",
    "        img_equal = cv2.GaussianBlur(img_equal, (5, 5), 0.9, 0.9)\n",
    "        \n",
    "        img_canny = cv2.Canny(img_equal, threshold1=90, threshold2=200)\n",
    "        img_canny = img_canny / 255\n",
    "\"\"\""
   ],
   "metadata": {
    "id": "5ZxMFsfa6l8k"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
